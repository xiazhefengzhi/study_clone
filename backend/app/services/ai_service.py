"""
AI Service for generating course content using Gemini 3.0
Based on gsap_animation_demo implementation - using GCP Vertex AI OpenAI-compatible endpoint
"""
import asyncio
import json
import os
from pathlib import Path
from typing import AsyncGenerator, List, Optional

from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage
from openai import AsyncOpenAI
import google.auth
import google.auth.transport.requests

from app.core.config import settings


class AIService:
    """AI service for generating animated course content using Gemini 3.0"""

    def __init__(self):
        """Initialize Gemini LLM via GCP Vertex AI"""
        # ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®
        self.project_id = os.getenv("GCP_PROJECT_ID", "gen-lang-client-0476802912")
        self.location = os.getenv("GCP_LOCATION", "global")  # Gemini 3.0 only supports global
        self.model_name = os.getenv("GCP_MODEL_NAME", "google/gemini-3-pro-preview")
        self.temperature = float(os.getenv("LLM_TEMPERATURE", "1"))

        # GCP OAuth credentials from env (for deployment)
        self.gcp_client_id = os.getenv("GCP_CLIENT_ID")
        self.gcp_client_secret = os.getenv("GCP_CLIENT_SECRET")
        self.gcp_refresh_token = os.getenv("GCP_REFRESH_TOKEN")

        # Auto-set GCP credentials file if not already set and no OAuth env vars
        if not os.getenv('GOOGLE_APPLICATION_CREDENTIALS') and not self.gcp_refresh_token:
            # Try multiple possible paths for local development
            possible_paths = [
                Path(__file__).parent.parent.parent.parent.parent.parent / 'gcp' / 'gcp_credentials.json',
                Path.home() / '.config' / 'gcloud' / 'application_default_credentials.json',
            ]
            for cred_path in possible_paths:
                if cred_path.exists():
                    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = str(cred_path)
                    print(f"Using GCP credentials file: {cred_path}")
                    break

        # Initialize LLM client
        self._init_llm()
        print(f"AI Service Initialized: Gemini 3.0 ({self.model_name})")

    def _init_llm(self):
        """Initialize LLM client with GCP auth or OpenRouter fallback"""
        try:
            # Method 1: Use OAuth credentials from environment variables (for deployment)
            if self.gcp_refresh_token and self.gcp_client_id and self.gcp_client_secret:
                from google.oauth2.credentials import Credentials
                credentials = Credentials(
                    token=None,
                    refresh_token=self.gcp_refresh_token,
                    client_id=self.gcp_client_id,
                    client_secret=self.gcp_client_secret,
                    token_uri="https://oauth2.googleapis.com/token",
                    scopes=["https://www.googleapis.com/auth/cloud-platform"]
                )
                credentials.refresh(google.auth.transport.requests.Request())
                print("Using GCP OAuth credentials from environment variables")
            else:
                # Method 2: Use default credentials (local development with JSON file)
                credentials, _ = google.auth.default(
                    scopes=["https://www.googleapis.com/auth/cloud-platform"]
                )
                credentials.refresh(google.auth.transport.requests.Request())
                print("Using GCP default credentials")

            # Build Vertex AI OpenAI-compatible endpoint for Gemini 3.0 (global region)
            base_url = (
                f"https://aiplatform.googleapis.com"
                f"/v1/projects/{self.project_id}/locations/{self.location}/endpoints/openapi"
            )

            # Create async client
            self.client = AsyncOpenAI(
                api_key=credentials.token,
                base_url=base_url
            )
            self.use_gcp = True
            print("Using GCP Vertex AI endpoint")

        except Exception as e:
            # GCP auth failed, use OpenRouter as fallback
            print(f"Warning: GCP auth failed ({e}), using OpenRouter fallback")

            # ä»ç¯å¢ƒå˜é‡è¯»å– OpenRouter é…ç½®
            openrouter_key = os.getenv("OPENROUTER_API_KEY") or settings.OPENAI_API_KEY
            openrouter_base = os.getenv("OPENROUTER_BASE_URL", "https://openrouter.ai/api/v1")
            fallback_model = os.getenv("OPENROUTER_MODEL", "google/gemini-2.5-flash-preview-09-2025")

            if not openrouter_key:
                raise ValueError("No API key configured. Set OPENROUTER_API_KEY or OPENAI_API_KEY in .env")

            self.client = AsyncOpenAI(
                api_key=openrouter_key,
                base_url=openrouter_base
            )
            self.model_name = fallback_model
            self.use_gcp = False
            print(f"Using OpenRouter fallback with model: {fallback_model}")

    def _build_prompt(
        self,
        content: str,
        style: str = "standard",
        difficulty: str = "intermediate",
        title: str = "",
    ) -> str:
        """Build the system prompt for content generation using GSAP animation approach"""

        # Style descriptions
        style_prompts = {
            "standard": "ä½¿ç”¨æ ‡å‡†çš„ã€ä¸“ä¸šçš„è®²è§£é£æ ¼ï¼Œæ¸…æ™°æ˜“æ‡‚",
            "humorous": "ä½¿ç”¨å¹½é»˜é£è¶£çš„æ–¹å¼è®²è§£ï¼Œè®©å­¦ä¹ å˜å¾—è½»æ¾æœ‰è¶£",
            "academic": "ä½¿ç”¨å­¦æœ¯æ€§çš„ã€ä¸¥è°¨çš„é£æ ¼ï¼Œæ³¨é‡ç†è®ºæ·±åº¦",
            "storytelling": "ä½¿ç”¨æ•…äº‹åŒ–çš„å™äº‹æ–¹å¼ï¼Œé€šè¿‡æ•…äº‹å¼•å¯¼å­¦ä¹ ",
            "practical": "æ³¨é‡å®è·µåº”ç”¨ï¼Œç»“åˆå®é™…æ¡ˆä¾‹å’Œåº”ç”¨åœºæ™¯",
            "eli5": "ç”¨æœ€ç®€å•çš„æ¯”å–»ï¼Œè¿äº”å²å°å­©éƒ½èƒ½å¬æ‡‚",
            "casual": "åƒæœ‹å‹åœ¨å’–å•¡å…èŠå¤©ä¸€æ ·è½»æ¾è‡ªç„¶",
            "tech": "æ·±å…¥åº•å±‚åŸç†ï¼Œç¡¬æ ¸æŠ€æœ¯æµ"
        }

        # Difficulty descriptions
        difficulty_prompts = {
            "beginner": "é€‚åˆåˆå­¦è€…ï¼Œä½¿ç”¨ç®€å•çš„è¯­è¨€å’ŒåŸºç¡€æ¦‚å¿µ",
            "intermediate": "é€‚åˆæœ‰ä¸€å®šåŸºç¡€çš„å­¦ä¹ è€…ï¼Œå¹³è¡¡æ·±åº¦å’Œå¹¿åº¦",
            "advanced": "é€‚åˆé«˜çº§å­¦ä¹ è€…ï¼Œæ·±å…¥è®²è§£å¤æ‚æ¦‚å¿µå’Œé«˜çº§åº”ç”¨"
        }

        style_desc = style_prompts.get(style, style_prompts.get("standard"))
        difficulty_desc = difficulty_prompts.get(difficulty, difficulty_prompts.get("intermediate"))

        # GSAP-based animation system prompt (based on gsap_animation_demo)
        system_prompt = f"""# ROLE: ä½ æ˜¯ä¸€ä½é¡¶å°–çš„ Motion Graphics è®¾è®¡å¸ˆ + èµ„æ·±æ•™è‚²çºªå½•ç‰‡å¯¼æ¼”
ä½ ä¸æ˜¯åœ¨å†™ä»£ç  - ä½ åœ¨**æ‹ä¸€éƒ¨å¼•äººå…¥èƒœçš„æ·±åº¦æ•™è‚²çŸ­ç‰‡**ã€‚

# ğŸ¯ ç¬¬ä¸€åŸåˆ™: CINEMATIC ENGAGEMENT (ç”µå½±çº§æ²‰æµ¸æ„Ÿ)

## 1. å®å¤§çš„æ—¶é—´å™äº‹ (Epic Timeline)
- **æ—¶é•¿è¦æ±‚**: ç›®æ ‡æ—¶é•¿ **3-5åˆ†é’Ÿ** (180-300ç§’)ã€‚å¿…é¡»æ·±å…¥å±•å¼€è¯é¢˜ï¼Œæ‹’ç»æµ…å°è¾„æ­¢ã€‚
- **å•ä¸€ GSAP Timeline**: æ‰€æœ‰åŠ¨ç”»ç”±ä¸€ä¸ªä¸» Timeline é©±åŠ¨ï¼Œç¡®ä¿æµç•…çš„å™äº‹èŠ‚å¥ã€‚
- **ç¦æ­¢ä»»ä½•äº¤äº’**: è§‚ä¼—æ˜¯æ²‰æµ¸å¼è§‚çœ‹è€…ï¼Œä¸è¦æ‰“æ–­ä»–ä»¬çš„ä½“éªŒ (æ—  hover/click/scroll)ã€‚

## 2. è§†å¬è¯­è¨€åŒæ­¥ (Audio-Visual Sync)
- **å­—å¹•é©±åŠ¨ç”»é¢**: å­—å¹•æ˜¯è„šæœ¬ï¼Œç”»é¢æ˜¯æ¼”ç»ã€‚å­—å¹•å‡ºç°æ—¶ï¼Œç”»é¢å¿…é¡»æœ‰é…åˆçš„åŠ¨æ€æ¼”ç»(é«˜äº®/ç§»åŠ¨/ç¼©æ”¾/å˜æ¢)ã€‚
- **åŒè¯­å­—å¹•**: æ¯ä¸ªåœºæ™¯éƒ½å¿…é¡»æœ‰ç²¾ç¡®å¯¹åº”çš„ä¸­è‹±åŒè¯­å­—å¹•ï¼Œè¾…åŠ©å…¨çƒè§‚ä¼—ç†è§£ã€‚

## 3. ä¸“ä¸šçš„è§†è§‰åŒ…è£… (Pro HUD)
- **è¿›åº¦æ¡**: åº•éƒ¨å¸¸é©»è¿›åº¦æ¡ï¼Œå®æ—¶åæ˜ 3-5åˆ†é’Ÿçš„æ’­æ”¾è¿›åº¦ã€‚
- **å­—å¹•å±‚**: åº•éƒ¨ç£¨ç ‚ç»ç’ƒè´¨æ„Ÿå­—å¹•æ¡ï¼Œæ¸…æ™°æ˜“è¯»ã€‚

# ğŸ‘¥ ç›®æ ‡è§‚ä¼—ä¸æ•ˆæœè¦æ±‚

- **ç›®æ ‡è§‚ä¼—**: å¯¹è¯¥ä¸»é¢˜æ„Ÿå…´è¶£çš„æ±‚çŸ¥è€…ï¼Œå¸Œæœ›åœ¨çŸ­æ—¶é—´å†…è·å¾—æ·±åº¦ã€ç³»ç»Ÿæ€§çš„ç†è§£ã€‚
- **è§†è§‰æ•ˆæœ**: 
    - ä½¿ç”¨ **Tailwind CSS** æ„å»ºç°ä»£ã€æç®€ä¸”é«˜çº§çš„ UIã€‚
    - åŠ¨ç”»å¿…é¡» **ä¸æ»‘æµç•… (Silky Smooth)**ï¼Œä½¿ç”¨ `power2.inOut` æˆ– `elastic` ç­‰é«˜çº§ç¼“åŠ¨å‡½æ•°ã€‚
    - é¿å…æ¯ç‡¥çš„æ–‡å­—å †ç Œï¼Œ**å¤šç”¨å›¾ç¤ºã€å›¾æ ‡ã€æŠ½è±¡å‡ ä½•å›¾å½¢** æ¥å¯è§†åŒ–æ¦‚å¿µã€‚
    - è½¬åœºå¿…é¡»è‡ªç„¶ï¼Œä¸è¦ç¡¬åˆ‡ï¼Œä½¿ç”¨æ·¡å…¥æ·¡å‡ºã€æ»‘å…¥æ»‘å‡ºæˆ–å½¢çŠ¶å˜æ¢ã€‚
- **å†…å®¹æ·±åº¦**: 
    - 3-5åˆ†é’Ÿçš„æ—¶é—´å…è®¸ä½ è®²æ•…äº‹ã€‚è¦æœ‰**èµ·æ‰¿è½¬åˆ**ã€‚
    - å¼•å…¥ -> æ ¸å¿ƒæ¦‚å¿µæ‹†è§£ -> æ¡ˆä¾‹/ç±»æ¯” -> æ·±å…¥åˆ†æ -> æ€»ç»“/å‡åã€‚

# ğŸ“ å¼ºåˆ¶æ€§ DOM æ¶æ„: HUD åˆ†å±‚æ¨¡å¼

```html
<body class="bg-slate-950 overflow-hidden text-slate-100 font-sans antialiased">
  <!-- é¡¶å±‚: è§†é¢‘ UI (è¿›åº¦æ¡) -->
  <div id="video-ui-layer" class="fixed top-0 left-0 w-full z-[1000]">
    <div id="progress-bar" class="h-1.5 bg-gradient-to-r from-blue-500 via-purple-500 to-pink-500 w-0 shadow-[0_0_10px_rgba(168,85,247,0.5)]"></div>
  </div>

  <!-- ä¸­å±‚: å­—å¹• HUD (å›ºå®šåº•éƒ¨) -->
  <div id="subtitle-layer" class="fixed bottom-8 left-1/2 -translate-x-1/2 w-[90%] max-w-4xl z-[900]
       bg-black/60 backdrop-blur-xl border border-white/10 rounded-2xl px-8 py-6 text-center shadow-2xl transition-all duration-500">
    <p id="subtitle-zh" class="text-2xl md:text-3xl font-bold text-white mb-3 tracking-wide text-shadow-sm">ä¸»å­—å¹•</p>
    <p id="subtitle-en" class="text-lg md:text-xl text-gray-300 font-light tracking-wider">Subtitle</p>
  </div>

  <!-- åº•å±‚: ç”»é¢èˆå° (å…¨å±) -->
  <div id="canvas" class="relative w-screen h-screen flex items-center justify-center overflow-hidden bg-gradient-to-br from-slate-900 to-slate-950">
    <!-- åœºæ™¯å†…å®¹å°†é€šè¿‡ JS åŠ¨æ€æ³¨å…¥æˆ–é¢„å…ˆå®šä¹‰ -->
  </div>
</body>
```

# ğŸ­ å‰§æœ¬é©±åŠ¨å¼€å‘ (Script-Driven Development)

## å‰§æœ¬æ•°æ®ç»“æ„ (JavaScript å¿…é¡»åŒ…å«)

```javascript
// è¿™æ˜¯ä¸€ä¸ªé•¿è¾¾ 3-5 åˆ†é’Ÿçš„å‰§æœ¬ï¼Œstoryboard æ•°ç»„åº”è¯¥åŒ…å«è¶³å¤Ÿå¤šçš„åœºæ™¯ (20-50ä¸ªåœºæ™¯)
const storyboard = [
  {{
    startTime: 0,
    duration: 4, // è¿™æ˜¯ä¸€ä¸ªç‰‡å¤´ï¼Œç¨é•¿ä¸€ç‚¹
    scene: "intro",
    subtitle: {{ zh: "æ¬¢è¿æ¥åˆ°...", en: "Welcome to..." }},
    animation: function(tl) {{ 
        // æ¸…ç©ºç”»å¸ƒæˆ–éšè—å‰ä¸€ä¸ªåœºæ™¯
        // åˆ›å»ºå½“å‰åœºæ™¯å…ƒç´ 
        // åŠ¨ç”»é€»è¾‘ 
    }}
  }},
  // ... å¿…é¡»ç”Ÿæˆè¶³å¤Ÿå¤šçš„åœºæ™¯ä»¥å¡«æ»¡ 180-300 ç§’
];
```

## é©±åŠ¨å¼•æ“æ¨¡æ¿

```javascript
const mainTimeline = gsap.timeline({{
  defaults: {{ease: "power2.inOut"}},
  onUpdate: function() {{
    const progress = this.progress() * 100;
    gsap.set("#progress-bar", {{width: progress + "%"}});
  }}
}});

storyboard.forEach((scene, index) => {{
  // å­—å¹•åŠ¨ç”»
  mainTimeline.call(() => {{
    const zh = document.getElementById("subtitle-zh");
    const en = document.getElementById("subtitle-en");
    zh.innerText = scene.subtitle.zh;
    en.innerText = scene.subtitle.en;
    
    // å­—å¹•åˆ‡æ¢ç‰¹æ•ˆ
    gsap.fromTo(zh, {{opacity: 0, y: 20, filter: "blur(10px)"}}, {{opacity: 1, y: 0, filter: "blur(0px)", duration: 0.8, ease: "power3.out"}});
    gsap.fromTo(en, {{opacity: 0, y: 15, filter: "blur(5px)"}}, {{opacity: 1, y: 0, filter: "blur(0px)", duration: 0.8, delay: 0.1, ease: "power3.out"}});
  }}, null, scene.startTime);
  
  // åœºæ™¯åŠ¨ç”»
  scene.animation(mainTimeline);
}});

mainTimeline.play();
```

# ğŸ“¦ å¿…é¡»å¼•å…¥çš„åº“

```html
<head>
  <script src="https://cdn.tailwindcss.com"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/3.12.2/gsap.min.js"></script>
  <!-- å¼•å…¥æ›´å¤š GSAP æ’ä»¶ä»¥æ”¯æŒä¸°å¯Œæ•ˆæœ -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/3.12.2/TextPlugin.min.js"></script>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;800&family=Noto+Sans+SC:wght@300;400;700&display=swap" rel="stylesheet">
  <style>
    body {{ font-family: 'Inter', 'Noto Sans SC', sans-serif; }}
    .text-shadow-sm {{ text-shadow: 0 2px 4px rgba(0,0,0,0.5); }}
  </style>
</head>
```

# ğŸ¬ ç”¨æˆ·éœ€æ±‚

**ä¸»é¢˜**: {title or "æ™ºèƒ½ç”Ÿæˆè®²è§£"}
**å†…å®¹**: {content}
**è®²è§£é£æ ¼**: {style_desc}
**éš¾åº¦çº§åˆ«**: {difficulty_desc}

# ğŸ“„ è¾“å‡ºè¦æ±‚

è¯·ç›´æ¥è¾“å‡ºå®Œæ•´çš„ HTML ä»£ç ï¼ŒåŒ…å«:
1. å®Œæ•´çš„ <!DOCTYPE html> åˆ° </html>
2. HUD åˆ†å±‚ DOM ç»“æ„ (ä½¿ç”¨æä¾›çš„ç¾åŒ–ç‰ˆç»“æ„)
3. **storyboard æ•°ç»„å®šä¹‰**: å¿…é¡»åŒ…å«è¶³å¤Ÿå¤šçš„åœºæ™¯ (20-50ä¸ª) ä»¥è¦†ç›– **3-5åˆ†é’Ÿ** çš„æ—¶é•¿ã€‚
4. GSAP é©±åŠ¨å¼•æ“ä»£ç 
5. å­—å¹•ä¸ç”»é¢ç²¾ç¡®åŒæ­¥
6. è¿›åº¦æ¡å®æ—¶æ›´æ–°
7. **æ€»æ—¶é•¿èŒƒå›´**: 180ç§’ - 300ç§’ (3-5åˆ†é’Ÿ)ã€‚è¯·åŠ¡å¿…è§„åˆ’å¥½å†…å®¹é‡ã€‚

**ç¦æ­¢**:
- çœç•¥ä»»ä½•ä»£ç 
- ä½¿ç”¨äº¤äº’äº‹ä»¶(click, hover)
- å­—å¹•å’ŒåŠ¨ç”»ä¸åŒæ­¥
- æ²¡æœ‰è¿›åº¦æ¡
- ç¡¬åˆ‡åœºæ™¯(æ²¡æœ‰è½¬åœº)
- **æ—¶é•¿è¿‡çŸ­ (å°‘äº3åˆ†é’Ÿ)**

ä¸è¦åŒ…å« markdown ä»£ç å—æ ‡è®°(```html)ï¼Œç›´æ¥è¿”å›ä»£ç ã€‚"""

        return system_prompt

    async def generate_course_content_stream(
        self,
        content: str,
        style: str = "standard",
        difficulty: str = "intermediate",
        title: str = "",
        history: Optional[List[dict]] = None,
    ) -> AsyncGenerator[str, None]:
        """
        Generate course content with streaming response using Gemini 3.0

        Args:
            content: Source content (from document or text input)
            style: Presentation style
            difficulty: Difficulty level
            title: Course title
            history: Chat history for context

        Yields:
            JSON chunks with generated HTML tokens
        """
        history = history or []
        system_prompt = self._build_prompt(content, style, difficulty, title)

        # Build messages
        messages = [
            {"role": "system", "content": system_prompt},
        ]

        # Add history if any
        for msg in history:
            messages.append({"role": msg.get("role", "user"), "content": msg.get("content", "")})

        try:
            # Stream response from Gemini 3.0
            response = await self.client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                stream=True,
                temperature=self.temperature,
            )

            async for chunk in response:
                if chunk.choices and chunk.choices[0].delta.content:
                    token = chunk.choices[0].delta.content
                    payload = json.dumps({"token": token}, ensure_ascii=False)
                    yield f"data: {payload}\n\n"

        except Exception as e:
            import traceback
            print(f"Gemini 3.0 Error: {e}")
            traceback.print_exc()
            yield f"data: {json.dumps({'error': str(e)})}\n\n"
            return

        yield 'data: {"event":"[DONE]"}\n\n'

    async def generate_course_content(
        self,
        content: str,
        style: str = "standard",
        difficulty: str = "intermediate",
        title: str = "",
    ) -> str:
        """
        Generate course content (non-streaming)

        Returns:
            Complete HTML content as string
        """
        accumulated = ""

        async for chunk in self.generate_course_content_stream(
            content, style, difficulty, title
        ):
            if chunk.startswith("data: "):
                try:
                    data_str = chunk[6:].strip()
                    if not data_str: continue

                    data = json.loads(data_str)
                    if "token" in data:
                        accumulated += data["token"]
                    elif "error" in data:
                        raise Exception(data["error"])
                except json.JSONDecodeError:
                    continue

        return accumulated


# Singleton instance
ai_service = AIService()
